# The total bytes of memory the producer can use to buffer records waiting to be sent to the server. 
# If records are sent faster than they can be delivered to the server the producer will either block 
# or throw an exception based on the preference specified by block.on.buffer.full
# (134217728 128M) (268435456 256M)
buffer.memory=134217728

# The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition.
# This helps performance on both the client and the server. This configuration controls the default batch size in bytes.
# (4194304 4M) (2097152 2M)
# batch.size/max.request.size=1/20
batch.size=52428

# The maximum size of a request. This is also effectively a cap on the maximum record size.
# (104857600 100M) (83886080 80M)
max.request.size=104857600

# The size of the TCP receive buffer to use when reading data
receive.buffer.bytes=2097152

# The size of the TCP send buffer to use when sending data
send.buffer.bytes=2097152

# specify the compression codec for all data generated: none , gzip, snappy.
# the old config values work as well: 0, 1, 2 for none, gzip, snappy, respectivally
compression.type=snappy

block.on.buffer.full=false

acks=0

retries=0

linger.ms=150

# The configuration controls how long KafkaProducer.send() and KafkaProducer.partitionsFor() will block.
# These methods can be blocked either because the buffer is full or metadata unavailable.Blocking
# in the user-supplied serializers or partitioner will not be counted against this timeout.
max.block.ms=0

# The configuration controls the maximum amount of time the client will wait for the response of a request.
# If the response is not received before the timeout elapses the client will resend the request
# if necessary or fail the request if retries are exhausted.
request.timeout.ms=30000

metadata.fetch.timeout.ms=5000